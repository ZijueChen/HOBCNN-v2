{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numm = 256\n",
    "RGBD_path = 'data_combined\\\\'# dataset path\n",
    "point_path = 'point_folder\\\\'# point path for cross validation\n",
    "GT_path = 'GT_l\\\\'# ground truth path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross validation\n",
    "pic = np.zeros([1,1])\n",
    "def cross_validation(validnum):\n",
    "    shutil.rmtree(point_path + 'train')\n",
    "    shutil.rmtree(point_path + 'test')\n",
    "    os.mkdir(point_path + 'train')\n",
    "    os.mkdir(point_path + 'test')\n",
    "    for i in range(5):\n",
    "        files = glob(point_path + 'group' + str(i) + '\\\\*.png')\n",
    "        if i == validnum:\n",
    "            for file in files:\n",
    "                name = list(file.split('\\\\'))[-1]\n",
    "                cv2.imwrite(point_path + 'test\\\\' + name, pic)\n",
    "        else:\n",
    "            for file in files:\n",
    "                name = list(file.split('\\\\'))[-1]\n",
    "                cv2.imwrite(point_path + 'train\\\\' + name, pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set 'validnum' here to change the data in 'train' and 'test' folder\n",
    "validnum = 2\n",
    "cross_validation(validnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 500\n",
    "BATCH_SIZE = 8\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "# STEPS_PER_EPOCH = 512 // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre-processing steps\n",
    "# Enable only one of the following cells:\n",
    "# Summer (Baseline)\n",
    "# Summer/Winter\n",
    "# Summer concat Winter\n",
    "# Summer concat WinterGT\n",
    "# 2Inputs Summer&Winter\n",
    "# 2Inputs Summer&WinterGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDER CONSTRUCTION____________\n",
    "# Summer (Baseline)\n",
    "# @tf.function\n",
    "# def load(point_file):\n",
    "#     name = tf.strings.split(point_file,'\\\\')[-1]\n",
    "\n",
    "#     RGBD = tf.io.read_file(RGBD_path + name)\n",
    "#     GT = tf.io.read_file(GT_path + name)\n",
    "#     RGBD = tf.image.decode_png(RGBD)\n",
    "#     GT = tf.image.decode_png(GT)\n",
    "    \n",
    "#     h, w = tf.shape(RGBD)[0], tf.shape(RGBD)[1]\n",
    "#     h, w = h // 2, w // 2\n",
    "#     RGBD = RGBD[:h, w:, :]\n",
    "#     GT = GT[:, 2:, :]\n",
    "    \n",
    "#     RGBD = tf.cast(RGBD, tf.float32)\n",
    "#     GT = tf.cast(GT, tf.float32)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# # Normalizing the images to [0, 1]\n",
    "# def norm_reshape(RGBD, GT):\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     GT = tf.concat([GT2, GT1], -1)\n",
    "#     RGBD = RGBD / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4]) # 这里要改\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# @tf.function()\n",
    "# def flip_norm_reshape(RGBD, GT):\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     if tf.random.uniform(()) > 0.5:\n",
    "#         # Random mirroring\n",
    "#         RGBD = tf.image.flip_left_right(RGBD)\n",
    "#         GT = tf.concat([GT0, GT3], -1)\n",
    "#     else:\n",
    "#         GT = tf.concat([GT2, GT1], -1)\n",
    "        \n",
    "#     RGBD = RGBD / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4])\n",
    "    \n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_train(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = flip_norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_test(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "# input_channel = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer/Winter\n",
    "# @tf.function\n",
    "# def load(point_file):\n",
    "#     name = tf.strings.split(point_file,'\\\\')[-1]\n",
    "\n",
    "#     RGBD = tf.io.read_file(RGBD_path + name)\n",
    "#     GT = tf.io.read_file(GT_path + name)\n",
    "#     RGBD = tf.image.decode_png(RGBD)\n",
    "#     GT = tf.image.decode_png(GT)\n",
    "    \n",
    "#     h, w = tf.shape(RGBD)[0], tf.shape(RGBD)[1]\n",
    "#     h, w = h // 2, w // 2\n",
    "#     RGBD = RGBD[:h, :, :]\n",
    "# #     GT = GT[:, 2:, :]\n",
    "    \n",
    "#     RGBD = tf.cast(RGBD, tf.float32)\n",
    "#     GT = tf.cast(GT, tf.float32)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# # Normalizing the images to [0, 1]\n",
    "# def norm_reshape(RGBD, GT):\n",
    "#     GT = GT[:, 2:, :]\n",
    "# #     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "# #     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     GT = tf.concat([GT2, GT1], -1)\n",
    "#     RGBD = RGBD[:, 256:, :] / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4]) # 这里要改\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# @tf.function()\n",
    "# def flip_norm_reshape(RGBD, GT):\n",
    "#     if tf.random.uniform(()) > 0.5:\n",
    "#         RGBD = RGBD[:, 256:, :]\n",
    "#         GT = GT[:, 2:, :]\n",
    "#     else:\n",
    "#         RGBD = RGBD[:, :256, :]\n",
    "#         GT = GT[:, :2, :]\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     if tf.random.uniform(()) > 0.5:\n",
    "#             # Random mirroring\n",
    "#         RGBD = tf.image.flip_left_right(RGBD)\n",
    "#         GT = tf.concat([GT0, GT3], -1)\n",
    "#     else:\n",
    "#         GT = tf.concat([GT2, GT1], -1)\n",
    "    \n",
    "#     RGBD = RGBD / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4])\n",
    "    \n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_train(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = flip_norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_test(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "# input_channel = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer concat Winter\n",
    "# @tf.function\n",
    "# def load(point_file):\n",
    "#     name = tf.strings.split(point_file,'\\\\')[-1]\n",
    "\n",
    "#     RGBD = tf.io.read_file(RGBD_path + name)\n",
    "#     GT = tf.io.read_file(GT_path + name)\n",
    "#     RGBD = tf.image.decode_png(RGBD)\n",
    "#     GT = tf.image.decode_png(GT)\n",
    "    \n",
    "#     h, w = tf.shape(RGBD)[0], tf.shape(RGBD)[1]\n",
    "#     h, w = h // 2, w // 2\n",
    "#     RGBD_s = RGBD[:h, w:, :]\n",
    "#     RGBD_w = RGBD[:h, :w, :]\n",
    "#     RGBD = tf.concat([RGBD_s, RGBD_w], -1)\n",
    "#     GT = GT[:, 2:, :]\n",
    "    \n",
    "#     RGBD = tf.cast(RGBD, tf.float32)\n",
    "#     GT = tf.cast(GT, tf.float32)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# # Normalizing the images to [0, 1]\n",
    "# def norm_reshape(RGBD, GT):\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     GT = tf.concat([GT2, GT1], -1)\n",
    "#     RGBD = RGBD / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4]) # 这里要改\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# @tf.function()\n",
    "# def flip_norm_reshape(RGBD, GT):\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     if tf.random.uniform(()) > 0.5:\n",
    "#         # Random mirroring\n",
    "#         RGBD = tf.image.flip_left_right(RGBD)\n",
    "#         GT = tf.concat([GT0, GT3], -1)\n",
    "#     else:\n",
    "#         GT = tf.concat([GT2, GT1], -1)\n",
    "        \n",
    "#     RGBD = RGBD / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4])\n",
    "    \n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_train(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = flip_norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_test(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "# input_channel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer concat WinterGT\n",
    "# @tf.function\n",
    "# def load(point_file):\n",
    "#     name = tf.strings.split(point_file,'\\\\')[-1]\n",
    "\n",
    "#     image = tf.io.read_file(RGBD_path + name)\n",
    "#     GT = tf.io.read_file(GT_path + name)\n",
    "#     image = tf.image.decode_png(image)\n",
    "#     GT = tf.image.decode_png(GT)\n",
    "    \n",
    "#     h, w = tf.shape(image)[0], tf.shape(image)[1]\n",
    "#     h, w = h // 2, w // 2\n",
    "#     RGBD = image[:h, w:, :]\n",
    "#     refer = image[h:, :w, 0]\n",
    "    \n",
    "#     GT = GT[:, 2:, :]\n",
    "    \n",
    "#     refer = tf.reshape(refer, [h, w, 1])\n",
    "#     RGBD = tf.cast(RGBD, tf.float32)\n",
    "#     refer = tf.cast(refer, tf.float32)#[:,:,0]\n",
    "#     GT = tf.cast(GT, tf.float32)\n",
    "#     RGBD = tf.concat([RGBD, refer], -1)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# # Normalizing the images to [0, 1]\n",
    "# def norm_reshape(RGBD, GT):\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     GT = tf.concat([GT2, GT1], -1)\n",
    "#     RGBD = RGBD / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4]) # 这里要改\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# @tf.function()\n",
    "# def flip_norm_reshape(RGBD, GT):\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     if tf.random.uniform(()) > 0.5:\n",
    "#      # Random mirroring\n",
    "#         RGBD = tf.image.flip_left_right(RGBD)\n",
    "#         GT = tf.concat([GT0, GT3], -1)\n",
    "#     else:\n",
    "#         GT = tf.concat([GT2, GT1], -1)\n",
    "        \n",
    "#     RGBD = RGBD / 255.\n",
    "#     GT = tf.reshape(GT, [numm*4])\n",
    "    \n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_train(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = flip_norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "\n",
    "# def load_image_test(point_file):\n",
    "#     RGBD, GT = load(point_file)\n",
    "#     RGBD, GT = norm_reshape(RGBD, GT)\n",
    "\n",
    "#     return RGBD, GT\n",
    "# input_channel = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Inputs Summer&Winter\n",
    "\n",
    "# def load(point_file):\n",
    "#     name = tf.strings.split(point_file,'\\\\')[-1]\n",
    "\n",
    "#     image = tf.io.read_file(RGBD_path + name)\n",
    "#     GT = tf.io.read_file(GT_path + name)\n",
    "#     image = tf.image.decode_png(image)\n",
    "#     GT = tf.image.decode_png(GT)\n",
    "    \n",
    "#     h, w = tf.shape(image)[0], tf.shape(image)[1]\n",
    "#     h, w = h // 2, w // 2\n",
    "#     RGBD = image[:h, w:, :]\n",
    "#     refer = image[:h, :w, :]\n",
    "\n",
    "#     GT = GT[:, 2:, :]\n",
    "# #     refer = tf.reshape(refer, [h, w, 1])\n",
    "    \n",
    "#     RGBD = tf.cast(RGBD, tf.float32)\n",
    "#     refer = tf.cast(refer, tf.float32)#[:,:,0]\n",
    "#     GT = tf.cast(GT, tf.float32)\n",
    "    \n",
    "#     return RGBD, refer, GT\n",
    "\n",
    "# # Normalizing the images to [0, 1]\n",
    "# def norm_reshape(RGBD, refer, GT):\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT = tf.concat([GT2, GT1], -1)\n",
    "    \n",
    "#     RGBD = RGBD / 255.\n",
    "#     refer = refer // 255\n",
    "#     GT = tf.reshape(GT, [numm*4])\n",
    "\n",
    "#     return RGBD, refer, GT\n",
    "\n",
    "# @tf.function()\n",
    "# def flip_norm_reshape(RGBD, refer, GT):\n",
    "#     GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "#     GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "#     GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "#     GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "#     if tf.random.uniform(()) > 0.5:\n",
    "#         # Random mirroring\n",
    "#         RGBD = tf.image.flip_left_right(RGBD)\n",
    "#         refer = tf.image.flip_left_right(refer)\n",
    "#         GT = tf.concat([GT0, GT3], -1)\n",
    "#     else:\n",
    "#         GT = tf.concat([GT2, GT1], -1)\n",
    "        \n",
    "#     RGBD = RGBD / 255.\n",
    "#     refer = refer // 255\n",
    "#     GT = tf.reshape(GT, [numm*4])\n",
    "    \n",
    "#     return RGBD, refer, GT\n",
    "\n",
    "# def load_image_train(point_file):\n",
    "#     RGBD, refer, GT = load(point_file)\n",
    "#     RGBD, refer, GT = flip_norm_reshape(RGBD, refer, GT)\n",
    "\n",
    "#     return {'input_3': RGBD, 'input_4': refer}, GT\n",
    "\n",
    "# def load_image_test(point_file):\n",
    "#     RGBD, refer, GT = load(point_file)\n",
    "#     RGBD, refer, GT = norm_reshape(RGBD, refer, GT)\n",
    "\n",
    "#     return {'input_3': RGBD, 'input_4': refer}, GT\n",
    "# refer_channel = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2Inputs Summer&WinterGT\n",
    "\n",
    "def load(point_file):\n",
    "    name = tf.strings.split(point_file,'\\\\')[-1]\n",
    "\n",
    "    image = tf.io.read_file(RGBD_path + name)\n",
    "    GT = tf.io.read_file(GT_path + name)\n",
    "    image = tf.image.decode_png(image)\n",
    "    GT = tf.image.decode_png(GT)\n",
    "    \n",
    "    h, w = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    h, w = h // 2, w // 2\n",
    "    RGBD = image[:h, w:, :]\n",
    "    refer = image[h:, :w, 0]\n",
    "\n",
    "    GT = GT[:, 2:, :]\n",
    "    refer = tf.reshape(refer, [h, w, 1])\n",
    "    \n",
    "    RGBD = tf.cast(RGBD, tf.float32)\n",
    "    refer = tf.cast(refer, tf.float32)#[:,:,0]\n",
    "    GT = tf.cast(GT, tf.float32)\n",
    "    \n",
    "    return RGBD, refer, GT\n",
    "\n",
    "# Normalizing the images to [0, 1]\n",
    "def norm_reshape(RGBD, refer, GT):\n",
    "    GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "    GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "    GT = tf.concat([GT2, GT1], -1)\n",
    "    \n",
    "    RGBD = RGBD / 255.\n",
    "    refer = refer // 255\n",
    "    GT = tf.reshape(GT, [numm*4])\n",
    "\n",
    "    return RGBD, refer, GT\n",
    "\n",
    "@tf.function()\n",
    "def flip_norm_reshape(RGBD, refer, GT):\n",
    "    GT0 = tf.reshape(GT[:, :, 0], [256, 2, 1])\n",
    "    GT1 = tf.reshape(GT[:, :, 1], [256, 2, 1])\n",
    "    GT2 = tf.reshape(GT[:, :, 2], [256, 2, 1])\n",
    "    GT3 = tf.reshape(GT[:, :, 3], [256, 2, 1])\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        # Random mirroring\n",
    "        RGBD = tf.image.flip_left_right(RGBD)\n",
    "        refer = tf.image.flip_left_right(refer)\n",
    "        GT = tf.concat([GT0, GT3], -1)\n",
    "    else:\n",
    "        GT = tf.concat([GT2, GT1], -1)\n",
    "        \n",
    "    RGBD = RGBD / 255.\n",
    "    refer = refer // 255\n",
    "    GT = tf.reshape(GT, [numm*4])\n",
    "    \n",
    "    return RGBD, refer, GT\n",
    "\n",
    "def load_image_train(point_file):\n",
    "    RGBD, refer, GT = load(point_file)\n",
    "    RGBD, refer, GT = flip_norm_reshape(RGBD, refer, GT)\n",
    "\n",
    "    return {'input_3': RGBD, 'input_4': refer}, GT\n",
    "\n",
    "def load_image_test(point_file):\n",
    "    RGBD, refer, GT = load(point_file)\n",
    "    RGBD, refer, GT = norm_reshape(RGBD, refer, GT)\n",
    "\n",
    "    return {'input_3': RGBD, 'input_4': refer}, GT\n",
    "refer_channel = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.list_files(point_path+'train\\\\*.png')\n",
    "train = train.map(load_image_train,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "train_dataset = train.shuffle(BUFFER_SIZE)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)#.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.list_files(point_path+'test\\\\*.png')\n",
    "test = test.map(load_image_test)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_channel = numm * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\61452\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 4 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB4(input_shape=[256, 256, 4], include_top=False, weights=None)#这里要改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptm = tf.keras.Model(inputs=base_model.input, outputs=base_model.output)\n",
    "# ptm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully Connection\n",
    "def IEF():\n",
    "    inputs = tf.keras.layers.Input(shape=[256,256,input_channel])\n",
    "    x = ptm(inputs)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(2048, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(output_channel)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 4)]     0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 8, 8, 1792)        17674257  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 114688)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              234883072 \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "=================================================================\n",
      "Total params: 255,705,105\n",
      "Trainable params: 255,579,896\n",
      "Non-trainable params: 125,209\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = IEF()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss=tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'weights_checkpoints/2_0'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "102/102 [==============================] - 37s 217ms/step - loss: 2049.8262 - val_loss: 2095.3948\n",
      "Epoch 2/400\n",
      "102/102 [==============================] - 20s 185ms/step - loss: 384.5825 - val_loss: 697.3754\n",
      "Epoch 3/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 391.5413 - val_loss: 423.7242\n",
      "Epoch 4/400\n",
      "102/102 [==============================] - 20s 184ms/step - loss: 351.4303 - val_loss: 577.7222\n",
      "Epoch 5/400\n",
      "102/102 [==============================] - 19s 183ms/step - loss: 349.1156 - val_loss: 390.4374\n",
      "Epoch 6/400\n",
      "102/102 [==============================] - 19s 183ms/step - loss: 309.9026 - val_loss: 277.7155\n",
      "Epoch 7/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 230.1657 - val_loss: 236.5085\n",
      "Epoch 8/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 211.7811 - val_loss: 266.3816\n",
      "Epoch 9/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 171.3237 - val_loss: 198.9168\n",
      "Epoch 10/400\n",
      "102/102 [==============================] - 20s 185ms/step - loss: 147.8275 - val_loss: 175.3997\n",
      "Epoch 11/400\n",
      "102/102 [==============================] - 19s 183ms/step - loss: 153.6712 - val_loss: 185.7229\n",
      "Epoch 12/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 137.2160 - val_loss: 186.7311\n",
      "Epoch 13/400\n",
      "102/102 [==============================] - 19s 183ms/step - loss: 126.0824 - val_loss: 138.4613\n",
      "Epoch 14/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 121.0966 - val_loss: 162.8490\n",
      "Epoch 15/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 112.0247 - val_loss: 149.4319\n",
      "Epoch 16/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 103.1235 - val_loss: 131.3302\n",
      "Epoch 17/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 95.6956 - val_loss: 202.8026\n",
      "Epoch 18/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 92.9164 - val_loss: 146.9665\n",
      "Epoch 19/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 83.9279 - val_loss: 131.6593\n",
      "Epoch 20/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 80.5688 - val_loss: 133.7280\n",
      "Epoch 21/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 81.4929 - val_loss: 103.2970\n",
      "Epoch 22/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 72.8755 - val_loss: 113.1232\n",
      "Epoch 23/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 74.7300 - val_loss: 103.3756\n",
      "Epoch 24/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 72.5947 - val_loss: 110.6903\n",
      "Epoch 25/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 71.7024 - val_loss: 124.0594\n",
      "Epoch 26/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 69.2730 - val_loss: 96.5551\n",
      "Epoch 27/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 65.0824 - val_loss: 108.4021\n",
      "Epoch 28/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 79.7382 - val_loss: 149.5314\n",
      "Epoch 29/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 63.8760 - val_loss: 87.1514\n",
      "Epoch 30/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 64.1035 - val_loss: 91.1324\n",
      "Epoch 31/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 58.1404 - val_loss: 90.0430\n",
      "Epoch 32/400\n",
      "102/102 [==============================] - 20s 191ms/step - loss: 55.8643 - val_loss: 103.6304\n",
      "Epoch 33/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 62.6820 - val_loss: 104.4484\n",
      "Epoch 34/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 52.6744 - val_loss: 117.0684\n",
      "Epoch 35/400\n",
      "102/102 [==============================] - 20s 188ms/step - loss: 55.6957 - val_loss: 100.1080\n",
      "Epoch 36/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 50.0236 - val_loss: 77.5110\n",
      "Epoch 37/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 59.7346 - val_loss: 104.1089\n",
      "Epoch 38/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 48.6142 - val_loss: 78.7422\n",
      "Epoch 39/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 50.2502 - val_loss: 96.5592\n",
      "Epoch 40/400\n",
      "102/102 [==============================] - 20s 190ms/step - loss: 45.7185 - val_loss: 88.4109\n",
      "Epoch 41/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 44.0510 - val_loss: 86.1903\n",
      "Epoch 42/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 46.4205 - val_loss: 93.8182\n",
      "Epoch 43/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 52.2326 - val_loss: 72.5453\n",
      "Epoch 44/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 37.9636 - val_loss: 70.2521\n",
      "Epoch 45/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 39.2468 - val_loss: 90.3628\n",
      "Epoch 46/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 44.3528 - val_loss: 87.7261\n",
      "Epoch 47/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 40.6109 - val_loss: 88.2315\n",
      "Epoch 48/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 38.9014 - val_loss: 75.6895\n",
      "Epoch 49/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 42.3040 - val_loss: 80.7550\n",
      "Epoch 50/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 44.6732 - val_loss: 73.4411\n",
      "Epoch 51/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 49.3760 - val_loss: 88.6519\n",
      "Epoch 52/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 36.1538 - val_loss: 75.0400\n",
      "Epoch 53/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 39.6170 - val_loss: 84.9020\n",
      "Epoch 54/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 39.4023 - val_loss: 89.3615\n",
      "Epoch 55/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 37.3227 - val_loss: 77.4893\n",
      "Epoch 56/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 33.9800 - val_loss: 72.3206\n",
      "Epoch 57/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 35.0400 - val_loss: 70.7282\n",
      "Epoch 58/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 37.3063 - val_loss: 71.7360\n",
      "Epoch 59/400\n",
      "102/102 [==============================] - 20s 191ms/step - loss: 36.9340 - val_loss: 76.4125\n",
      "Epoch 60/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 39.8163 - val_loss: 91.1434\n",
      "Epoch 61/400\n",
      "102/102 [==============================] - 20s 188ms/step - loss: 33.7123 - val_loss: 62.6205\n",
      "Epoch 62/400\n",
      "102/102 [==============================] - 20s 188ms/step - loss: 35.4843 - val_loss: 71.3314\n",
      "Epoch 63/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 39.8852 - val_loss: 87.9452\n",
      "Epoch 64/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 44.8077 - val_loss: 75.5649\n",
      "Epoch 65/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 35.9655 - val_loss: 78.5948\n",
      "Epoch 66/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 45.5478 - val_loss: 89.2563\n",
      "Epoch 67/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 34.7836 - val_loss: 65.6643\n",
      "Epoch 68/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 36.6400 - val_loss: 83.6565\n",
      "Epoch 69/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 37.0862 - val_loss: 94.6434\n",
      "Epoch 70/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 31.8932 - val_loss: 68.5916\n",
      "Epoch 71/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 33.2132 - val_loss: 73.3046\n",
      "Epoch 72/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 39.3695 - val_loss: 95.9363\n",
      "Epoch 73/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 35.8254 - val_loss: 79.2768\n",
      "Epoch 74/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 35.0335 - val_loss: 67.4282\n",
      "Epoch 75/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 34.3896 - val_loss: 62.8309\n",
      "Epoch 76/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 31.2480 - val_loss: 62.1788\n",
      "Epoch 77/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 58.6392 - val_loss: 257.0010\n",
      "Epoch 78/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 91.7492 - val_loss: 93.0884\n",
      "Epoch 79/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 46.3877 - val_loss: 63.3806\n",
      "Epoch 80/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 39.8795 - val_loss: 74.6080\n",
      "Epoch 81/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 39.3114 - val_loss: 76.8348\n",
      "Epoch 82/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 37.4263 - val_loss: 64.1554\n",
      "Epoch 83/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 36.4195 - val_loss: 54.5061\n",
      "Epoch 84/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 28.9086 - val_loss: 57.3833\n",
      "Epoch 85/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 27.2589 - val_loss: 66.9764\n",
      "Epoch 86/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 26.0137 - val_loss: 48.9106\n",
      "Epoch 87/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 26.8835 - val_loss: 56.0023\n",
      "Epoch 88/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 24.9571 - val_loss: 48.8773\n",
      "Epoch 89/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 21.6644 - val_loss: 50.6916\n",
      "Epoch 90/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 23.2458 - val_loss: 53.6377\n",
      "Epoch 91/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 24.2129 - val_loss: 57.5873\n",
      "Epoch 92/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 26.2574 - val_loss: 53.5237\n",
      "Epoch 93/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 23.2010 - val_loss: 60.8801\n",
      "Epoch 94/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 22.9038 - val_loss: 51.5134\n",
      "Epoch 95/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 21.7264 - val_loss: 55.0428\n",
      "Epoch 96/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 22.5719 - val_loss: 55.4560\n",
      "Epoch 97/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 23.9997 - val_loss: 57.8651\n",
      "Epoch 98/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 22.3985 - val_loss: 54.0768\n",
      "Epoch 99/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 24.0590 - val_loss: 50.3081\n",
      "Epoch 100/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 19.7990 - val_loss: 56.1771\n",
      "Epoch 101/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 21.7682 - val_loss: 54.5859\n",
      "Epoch 102/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 30.0373 - val_loss: 187.7701\n",
      "Epoch 103/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 46.6158 - val_loss: 128.6518\n",
      "Epoch 104/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 46.5217 - val_loss: 70.8064\n",
      "Epoch 105/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 38.2927 - val_loss: 129.9563\n",
      "Epoch 106/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 34.5128 - val_loss: 59.4376\n",
      "Epoch 107/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 28.9189 - val_loss: 59.5298\n",
      "Epoch 108/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 28.2490 - val_loss: 57.2425\n",
      "Epoch 109/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 25.3796 - val_loss: 54.5826\n",
      "Epoch 110/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 25.1023 - val_loss: 52.6990\n",
      "Epoch 111/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 23.4945 - val_loss: 54.7116\n",
      "Epoch 112/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 20.7927 - val_loss: 44.9398\n",
      "Epoch 113/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 21.0679 - val_loss: 54.5298\n",
      "Epoch 114/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 24.7141 - val_loss: 56.9298\n",
      "Epoch 115/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 21.0944 - val_loss: 54.3714\n",
      "Epoch 116/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 18.7145 - val_loss: 51.2168\n",
      "Epoch 117/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 20.5607 - val_loss: 52.6397\n",
      "Epoch 118/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 23.3086 - val_loss: 48.4099\n",
      "Epoch 119/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 21.7946 - val_loss: 49.0875\n",
      "Epoch 120/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 22.5912 - val_loss: 49.6581\n",
      "Epoch 121/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 18.5094 - val_loss: 46.7981\n",
      "Epoch 122/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 20.6001 - val_loss: 47.9602\n",
      "Epoch 123/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 20.0976 - val_loss: 58.3959\n",
      "Epoch 124/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 22.9964 - val_loss: 58.2589\n",
      "Epoch 125/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 20.1427 - val_loss: 48.6350\n",
      "Epoch 126/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 17.9165 - val_loss: 46.5134\n",
      "Epoch 127/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 17.6871 - val_loss: 48.2840\n",
      "Epoch 128/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 17.2344 - val_loss: 55.0785\n",
      "Epoch 129/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 19.5222 - val_loss: 48.5219\n",
      "Epoch 130/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 18.4423 - val_loss: 51.9211\n",
      "Epoch 131/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 17.8695 - val_loss: 57.9561\n",
      "Epoch 132/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 21.2867 - val_loss: 74.0004\n",
      "Epoch 133/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 19.2890 - val_loss: 50.2219\n",
      "Epoch 134/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 20.4345 - val_loss: 49.5139\n",
      "Epoch 135/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 22.1621 - val_loss: 56.6570\n",
      "Epoch 136/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 18.5142 - val_loss: 49.9878\n",
      "Epoch 137/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 20.4447 - val_loss: 54.2038\n",
      "Epoch 138/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 20.5681 - val_loss: 69.9771\n",
      "Epoch 139/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 22.0530 - val_loss: 83.9230\n",
      "Epoch 140/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 20.2926 - val_loss: 46.9815\n",
      "Epoch 141/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 19.7326 - val_loss: 52.7880\n",
      "Epoch 142/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 17.4823 - val_loss: 45.3712\n",
      "Epoch 143/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 20.5611 - val_loss: 47.7599\n",
      "Epoch 144/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 17.3982 - val_loss: 52.2151\n",
      "Epoch 145/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 21.1259 - val_loss: 56.7261\n",
      "Epoch 146/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 33.9297 - val_loss: 91.4581\n",
      "Epoch 147/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 41.2909 - val_loss: 67.4080\n",
      "Epoch 148/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 26.2369 - val_loss: 43.9622\n",
      "Epoch 149/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 20.8544 - val_loss: 45.0512\n",
      "Epoch 150/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 20.6925 - val_loss: 46.3298\n",
      "Epoch 151/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 18.4748 - val_loss: 41.2122\n",
      "Epoch 152/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 19.0717 - val_loss: 48.2361\n",
      "Epoch 153/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 19s 186ms/step - loss: 19.2139 - val_loss: 44.3586\n",
      "Epoch 154/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 17.4137 - val_loss: 42.9546\n",
      "Epoch 155/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 17.8206 - val_loss: 45.3711\n",
      "Epoch 156/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 17.5655 - val_loss: 49.1950\n",
      "Epoch 157/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 15.9415 - val_loss: 52.2518\n",
      "Epoch 158/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 17.4450 - val_loss: 50.0950\n",
      "Epoch 159/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 14.7536 - val_loss: 45.5439\n",
      "Epoch 160/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.0393 - val_loss: 40.7404\n",
      "Epoch 161/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 15.7217 - val_loss: 44.1891\n",
      "Epoch 162/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 14.8504 - val_loss: 43.0046\n",
      "Epoch 163/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 15.6016 - val_loss: 46.4678\n",
      "Epoch 164/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 15.5508 - val_loss: 39.5394\n",
      "Epoch 165/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 13.2507 - val_loss: 47.8817\n",
      "Epoch 166/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 15.2493 - val_loss: 41.9245\n",
      "Epoch 167/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 13.7024 - val_loss: 39.4249\n",
      "Epoch 168/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 14.0870 - val_loss: 48.6529\n",
      "Epoch 169/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.1666 - val_loss: 42.3270\n",
      "Epoch 170/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 13.1787 - val_loss: 40.7192\n",
      "Epoch 171/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.9112 - val_loss: 42.6654\n",
      "Epoch 172/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 13.6441 - val_loss: 41.0914\n",
      "Epoch 173/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 13.7607 - val_loss: 44.8170\n",
      "Epoch 174/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.7661 - val_loss: 50.9143\n",
      "Epoch 175/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 14.1477 - val_loss: 44.7981\n",
      "Epoch 176/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.5778 - val_loss: 45.1470\n",
      "Epoch 177/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.2644 - val_loss: 43.0469\n",
      "Epoch 178/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.0921 - val_loss: 43.9933\n",
      "Epoch 179/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.6369 - val_loss: 43.1141\n",
      "Epoch 180/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.3045 - val_loss: 43.4140\n",
      "Epoch 181/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 15.3667 - val_loss: 50.1153\n",
      "Epoch 182/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.8942 - val_loss: 44.2651\n",
      "Epoch 183/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.5089 - val_loss: 47.2617\n",
      "Epoch 184/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.4468 - val_loss: 42.9345\n",
      "Epoch 185/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 13.7750 - val_loss: 47.8905\n",
      "Epoch 186/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.0482 - val_loss: 46.3256\n",
      "Epoch 187/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 12.4925 - val_loss: 48.0714\n",
      "Epoch 188/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.4236 - val_loss: 44.4075\n",
      "Epoch 189/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.6271 - val_loss: 46.2793\n",
      "Epoch 190/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 12.5351 - val_loss: 43.3023\n",
      "Epoch 191/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 15.5914 - val_loss: 47.7684\n",
      "Epoch 192/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 13.3521 - val_loss: 45.2617\n",
      "Epoch 193/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 15.1021 - val_loss: 48.1254\n",
      "Epoch 194/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 14.9882 - val_loss: 43.5522\n",
      "Epoch 195/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 12.2361 - val_loss: 41.2785\n",
      "Epoch 196/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 12.2017 - val_loss: 52.2810\n",
      "Epoch 197/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.7013 - val_loss: 45.6206\n",
      "Epoch 198/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.9038 - val_loss: 44.6478\n",
      "Epoch 199/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 12.7892 - val_loss: 44.5112\n",
      "Epoch 200/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 12.9131 - val_loss: 41.8979\n",
      "Epoch 201/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 11.9713 - val_loss: 47.3406\n",
      "Epoch 202/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.3557 - val_loss: 41.1765\n",
      "Epoch 203/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.6327 - val_loss: 43.4315\n",
      "Epoch 204/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 11.6053 - val_loss: 44.6190\n",
      "Epoch 205/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.3520 - val_loss: 42.9250\n",
      "Epoch 206/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.5334 - val_loss: 41.0969\n",
      "Epoch 207/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 11.3398 - val_loss: 41.6327\n",
      "Epoch 208/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 11.4964 - val_loss: 38.2451\n",
      "Epoch 209/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 11.4836 - val_loss: 41.1415\n",
      "Epoch 210/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 13.9600 - val_loss: 48.1454\n",
      "Epoch 211/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 11.5223 - val_loss: 37.6430\n",
      "Epoch 212/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 12.1655 - val_loss: 43.9630\n",
      "Epoch 213/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.2422 - val_loss: 46.8336\n",
      "Epoch 214/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 15.7100 - val_loss: 47.3219\n",
      "Epoch 215/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 18.0720 - val_loss: 48.1208\n",
      "Epoch 216/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.8586 - val_loss: 54.8029\n",
      "Epoch 217/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.9604 - val_loss: 46.4866\n",
      "Epoch 218/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.1346 - val_loss: 46.1812\n",
      "Epoch 219/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 11.8328 - val_loss: 43.3665\n",
      "Epoch 220/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 12.1301 - val_loss: 42.8550\n",
      "Epoch 221/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 10.9297 - val_loss: 40.2814\n",
      "Epoch 222/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.1322 - val_loss: 41.7059\n",
      "Epoch 223/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 9.9820 - val_loss: 42.0245\n",
      "Epoch 224/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 10.5028 - val_loss: 42.1230\n",
      "Epoch 225/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 10.0866 - val_loss: 40.2366\n",
      "Epoch 226/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.7573 - val_loss: 41.7524\n",
      "Epoch 227/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 11.4446 - val_loss: 40.2106\n",
      "Epoch 228/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 10.2294 - val_loss: 40.9276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.0980 - val_loss: 42.1056\n",
      "Epoch 230/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.6806 - val_loss: 47.6447\n",
      "Epoch 231/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 12.2510 - val_loss: 47.5626\n",
      "Epoch 232/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.3077 - val_loss: 40.4709\n",
      "Epoch 233/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.4218 - val_loss: 43.3401\n",
      "Epoch 234/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 10.8547 - val_loss: 39.8547\n",
      "Epoch 235/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.8025 - val_loss: 47.8203\n",
      "Epoch 236/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.4357 - val_loss: 38.6849\n",
      "Epoch 237/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 9.6494 - val_loss: 40.9795\n",
      "Epoch 238/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.4158 - val_loss: 39.3124\n",
      "Epoch 239/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 9.5630 - val_loss: 44.7556\n",
      "Epoch 240/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.4081 - val_loss: 38.0083\n",
      "Epoch 241/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.3454 - val_loss: 42.8165\n",
      "Epoch 242/400\n",
      "102/102 [==============================] - 20s 188ms/step - loss: 10.4958 - val_loss: 44.0031\n",
      "Epoch 243/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 11.4109 - val_loss: 46.0427\n",
      "Epoch 244/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.9968 - val_loss: 44.8688\n",
      "Epoch 245/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 9.8515 - val_loss: 40.9785\n",
      "Epoch 246/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 9.2586 - val_loss: 41.2413\n",
      "Epoch 247/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.6589 - val_loss: 42.2012\n",
      "Epoch 248/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.2907 - val_loss: 46.5311\n",
      "Epoch 249/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 10.2824 - val_loss: 39.4989\n",
      "Epoch 250/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.0850 - val_loss: 39.1379\n",
      "Epoch 251/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 9.1708 - val_loss: 38.1154\n",
      "Epoch 252/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.0203 - val_loss: 43.9282\n",
      "Epoch 253/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.1090 - val_loss: 40.8198\n",
      "Epoch 254/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.9706 - val_loss: 44.8910\n",
      "Epoch 255/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 9.7149 - val_loss: 37.3486\n",
      "Epoch 256/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 9.4008 - val_loss: 39.1685\n",
      "Epoch 257/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 9.8948 - val_loss: 42.2136\n",
      "Epoch 258/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 14.7013 - val_loss: 51.3770\n",
      "Epoch 259/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 13.8292 - val_loss: 46.2712\n",
      "Epoch 260/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 11.1608 - val_loss: 47.4934\n",
      "Epoch 261/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 10.1796 - val_loss: 41.2701\n",
      "Epoch 262/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 10.7798 - val_loss: 41.9480\n",
      "Epoch 263/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.2618 - val_loss: 42.5416\n",
      "Epoch 264/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 10.3550 - val_loss: 38.5642\n",
      "Epoch 265/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 9.1984 - val_loss: 41.4515\n",
      "Epoch 266/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 10.9863 - val_loss: 40.6121\n",
      "Epoch 267/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.9594 - val_loss: 43.0022\n",
      "Epoch 268/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.4741 - val_loss: 40.2094\n",
      "Epoch 269/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.1038 - val_loss: 43.5169\n",
      "Epoch 270/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.9382 - val_loss: 42.9996\n",
      "Epoch 271/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 8.6730 - val_loss: 38.6371\n",
      "Epoch 272/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.2910 - val_loss: 37.7676\n",
      "Epoch 273/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 9.3831 - val_loss: 40.5524\n",
      "Epoch 274/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.6361 - val_loss: 40.9705\n",
      "Epoch 275/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.2820 - val_loss: 37.7406\n",
      "Epoch 276/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.2792 - val_loss: 37.9704\n",
      "Epoch 277/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.6839 - val_loss: 42.6171\n",
      "Epoch 278/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.3508 - val_loss: 37.8895\n",
      "Epoch 279/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.4750 - val_loss: 39.2499\n",
      "Epoch 280/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.0732 - val_loss: 36.9197\n",
      "Epoch 281/400\n",
      "102/102 [==============================] - 20s 186ms/step - loss: 8.5602 - val_loss: 39.7096\n",
      "Epoch 282/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 8.3806 - val_loss: 36.5605\n",
      "Epoch 283/400\n",
      "102/102 [==============================] - 20s 185ms/step - loss: 8.9292 - val_loss: 41.0288\n",
      "Epoch 284/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.2224 - val_loss: 37.3078\n",
      "Epoch 285/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.0182 - val_loss: 37.9577\n",
      "Epoch 286/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.3244 - val_loss: 49.3288\n",
      "Epoch 287/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.3421 - val_loss: 41.5980\n",
      "Epoch 288/400\n",
      "102/102 [==============================] - 20s 188ms/step - loss: 8.6525 - val_loss: 37.7814\n",
      "Epoch 289/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 10.1696 - val_loss: 44.6896\n",
      "Epoch 290/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.4658 - val_loss: 41.2035\n",
      "Epoch 291/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.5139 - val_loss: 38.7908\n",
      "Epoch 292/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.6430 - val_loss: 38.1588\n",
      "Epoch 293/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.0505 - val_loss: 39.1837\n",
      "Epoch 294/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 8.0445 - val_loss: 38.3218\n",
      "Epoch 295/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.3540 - val_loss: 38.6739\n",
      "Epoch 296/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.9004 - val_loss: 37.3359\n",
      "Epoch 297/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.9786 - val_loss: 46.0642\n",
      "Epoch 298/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.6786 - val_loss: 40.8176\n",
      "Epoch 299/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.0677 - val_loss: 41.0128\n",
      "Epoch 300/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 9.0280 - val_loss: 41.5438\n",
      "Epoch 301/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.6316 - val_loss: 38.3605\n",
      "Epoch 302/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 7.3564 - val_loss: 38.4393\n",
      "Epoch 303/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.3563 - val_loss: 39.2442\n",
      "Epoch 304/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.1253 - val_loss: 58.4978\n",
      "Epoch 305/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.7935 - val_loss: 40.6130\n",
      "Epoch 306/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.7263 - val_loss: 40.0848\n",
      "Epoch 307/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.5565 - val_loss: 40.7344\n",
      "Epoch 308/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.7886 - val_loss: 39.6266\n",
      "Epoch 309/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 8.7931 - val_loss: 42.4933\n",
      "Epoch 310/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.0659 - val_loss: 40.2967\n",
      "Epoch 311/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.2396 - val_loss: 38.5208\n",
      "Epoch 312/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.5539 - val_loss: 39.9089\n",
      "Epoch 313/400\n",
      "102/102 [==============================] - 20s 190ms/step - loss: 7.4711 - val_loss: 45.3280\n",
      "Epoch 314/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.0811 - val_loss: 40.7920\n",
      "Epoch 315/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.5769 - val_loss: 39.3812\n",
      "Epoch 316/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.8151 - val_loss: 38.3662\n",
      "Epoch 317/400\n",
      "102/102 [==============================] - 20s 188ms/step - loss: 7.2284 - val_loss: 37.3817\n",
      "Epoch 318/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.8080 - val_loss: 41.6672\n",
      "Epoch 319/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.7357 - val_loss: 37.6595\n",
      "Epoch 320/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 7.9733 - val_loss: 43.9837\n",
      "Epoch 321/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.7768 - val_loss: 41.8193\n",
      "Epoch 322/400\n",
      "102/102 [==============================] - 20s 190ms/step - loss: 7.7995 - val_loss: 40.7186\n",
      "Epoch 323/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 7.2166 - val_loss: 41.7271\n",
      "Epoch 324/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.9348 - val_loss: 41.2431\n",
      "Epoch 325/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 7.5939 - val_loss: 39.1623\n",
      "Epoch 326/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.9593 - val_loss: 39.3621\n",
      "Epoch 327/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 7.3678 - val_loss: 38.8321\n",
      "Epoch 328/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.6762 - val_loss: 40.0901\n",
      "Epoch 329/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 7.1614 - val_loss: 39.6878\n",
      "Epoch 330/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.0342 - val_loss: 43.1042\n",
      "Epoch 331/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.1652 - val_loss: 44.2733\n",
      "Epoch 332/400\n",
      "102/102 [==============================] - 20s 188ms/step - loss: 8.2184 - val_loss: 43.1117\n",
      "Epoch 333/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.6765 - val_loss: 41.1465\n",
      "Epoch 334/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 8.1710 - val_loss: 39.5949\n",
      "Epoch 335/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 7.4414 - val_loss: 38.6475\n",
      "Epoch 336/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.6588 - val_loss: 38.6327\n",
      "Epoch 337/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 6.9634 - val_loss: 42.0136\n",
      "Epoch 338/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 7.2045 - val_loss: 42.8117\n",
      "Epoch 339/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.1773 - val_loss: 40.8999\n",
      "Epoch 340/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.6926 - val_loss: 41.7929\n",
      "Epoch 341/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.5743 - val_loss: 42.3528\n",
      "Epoch 342/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.7979 - val_loss: 42.0484\n",
      "Epoch 343/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.2589 - val_loss: 37.9091\n",
      "Epoch 344/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.8893 - val_loss: 40.7860\n",
      "Epoch 345/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.2392 - val_loss: 40.9471\n",
      "Epoch 346/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 6.7728 - val_loss: 38.0786\n",
      "Epoch 347/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.5281 - val_loss: 38.1776\n",
      "Epoch 348/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.5408 - val_loss: 39.1614\n",
      "Epoch 349/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 8.2876 - val_loss: 38.1154\n",
      "Epoch 350/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.7402 - val_loss: 41.0559\n",
      "Epoch 351/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.6148 - val_loss: 38.9199\n",
      "Epoch 352/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 7.5956 - val_loss: 43.8750\n",
      "Epoch 353/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.9973 - val_loss: 44.0203\n",
      "Epoch 354/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.1610 - val_loss: 39.9421\n",
      "Epoch 355/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.8179 - val_loss: 39.4981\n",
      "Epoch 356/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.7417 - val_loss: 39.6602\n",
      "Epoch 357/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.6825 - val_loss: 35.8775\n",
      "Epoch 358/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 6.7061 - val_loss: 39.1154\n",
      "Epoch 359/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.8302 - val_loss: 38.1103\n",
      "Epoch 360/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.6881 - val_loss: 37.1905\n",
      "Epoch 361/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 6.4401 - val_loss: 37.6875\n",
      "Epoch 362/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.6447 - val_loss: 40.4859\n",
      "Epoch 363/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.8049 - val_loss: 42.4077\n",
      "Epoch 364/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 8.3581 - val_loss: 38.8537\n",
      "Epoch 365/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.9217 - val_loss: 46.8561\n",
      "Epoch 366/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.6999 - val_loss: 38.2070\n",
      "Epoch 367/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.4845 - val_loss: 39.0283\n",
      "Epoch 368/400\n",
      "102/102 [==============================] - 20s 196ms/step - loss: 6.2997 - val_loss: 39.0026\n",
      "Epoch 369/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 5.8123 - val_loss: 35.8286\n",
      "Epoch 370/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 5.9642 - val_loss: 39.9840\n",
      "Epoch 371/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 6.0366 - val_loss: 36.8362\n",
      "Epoch 372/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 6.2136 - val_loss: 36.4304\n",
      "Epoch 373/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.5667 - val_loss: 35.9644\n",
      "Epoch 374/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.2540 - val_loss: 40.1403\n",
      "Epoch 375/400\n",
      "102/102 [==============================] - 20s 187ms/step - loss: 6.7616 - val_loss: 36.6695\n",
      "Epoch 376/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.2808 - val_loss: 36.0047\n",
      "Epoch 377/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.2141 - val_loss: 37.2807\n",
      "Epoch 378/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 6.3791 - val_loss: 42.4290\n",
      "Epoch 379/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.3676 - val_loss: 36.2260\n",
      "Epoch 380/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 7.1594 - val_loss: 37.6089\n",
      "Epoch 381/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 19s 187ms/step - loss: 6.1229 - val_loss: 36.4271\n",
      "Epoch 382/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.1860 - val_loss: 38.0491\n",
      "Epoch 383/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.3413 - val_loss: 40.2972\n",
      "Epoch 384/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.9947 - val_loss: 75.2623\n",
      "Epoch 385/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 13.1455 - val_loss: 48.9604\n",
      "Epoch 386/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 10.8660 - val_loss: 49.7233\n",
      "Epoch 387/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 14.5703 - val_loss: 44.5939\n",
      "Epoch 388/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 9.4001 - val_loss: 42.8425\n",
      "Epoch 389/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 8.1451 - val_loss: 38.2833\n",
      "Epoch 390/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.3783 - val_loss: 38.2959\n",
      "Epoch 391/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 7.0541 - val_loss: 37.6827\n",
      "Epoch 392/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 6.4425 - val_loss: 37.6487\n",
      "Epoch 393/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 6.1606 - val_loss: 38.3048\n",
      "Epoch 394/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 5.9709 - val_loss: 38.1978\n",
      "Epoch 395/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 5.8850 - val_loss: 37.9051\n",
      "Epoch 396/400\n",
      "102/102 [==============================] - 19s 187ms/step - loss: 5.9715 - val_loss: 39.7348\n",
      "Epoch 397/400\n",
      "102/102 [==============================] - 19s 185ms/step - loss: 5.9171 - val_loss: 39.2006\n",
      "Epoch 398/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 5.7564 - val_loss: 38.2503\n",
      "Epoch 399/400\n",
      "102/102 [==============================] - 19s 186ms/step - loss: 5.7402 - val_loss: 37.2475\n",
      "Epoch 400/400\n",
      "102/102 [==============================] - 19s 184ms/step - loss: 5.7526 - val_loss: 38.1486\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 400\n",
    "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          validation_data=test_dataset,\n",
    "                          callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'], label='train loss')\n",
    "plt.plot(model_history.history['val_loss'], label='valid loss')\n",
    "plt.legend()\n",
    "plt.ylim(0, 100) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2ad49e85f40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable this prediction cell for:\n",
    "# Summer (Baseline)\n",
    "# Summer/Winter\n",
    "# Summer concat Winter\n",
    "# Summer concat WinterGT\n",
    "# def save_predictions():\n",
    "#     files = glob('point_folder\\\\test\\\\' + '*.png')\n",
    "#     for file in files:\n",
    "#         name = list(file.split('\\\\'))[-1]\n",
    "#         img = np.zeros([256,256])\n",
    "#         picture, _ = load_image_test(file)\n",
    "#         input_pic = np.reshape(picture, (1,256,256,input_channel))\n",
    "#         prediction = model.predict(input_pic)\n",
    "#         prediction = np.array(prediction).astype(int).reshape(256,2,2)\n",
    "#         for i in range(256):\n",
    "#             cv2.line(img, (prediction[i,0,0],i), (prediction[i,0,1],i), 255, 1)\n",
    "#             cv2.line(img, (prediction[i,1,0],i), (prediction[i,1,1],i), 255, 1)\n",
    "\n",
    "#         cv2.imwrite('prediction_HOB_w&s\\\\' + name, img)# change save path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable this prediction cell for:\n",
    "# 2Inputs Summer&Winter\n",
    "# 2Inputs Summer&WinterGT\n",
    "def save_predictions():\n",
    "    files = glob('point_folder\\\\test\\\\' + '*.png')\n",
    "    for file in files:\n",
    "        name = list(file.split('\\\\'))[-1]\n",
    "        img = np.zeros([256,256])\n",
    "        picture, _ = load_image_test(file)\n",
    "        input_pic, refer = list(picture.values())[0], list(picture.values())[1]\n",
    "        input_pic = np.reshape(input_pic, (1,256,256,4))\n",
    "        refer = np.reshape(refer, (1,256,256,refer_channel))\n",
    "        prediction = model.predict([input_pic, refer])\n",
    "        prediction = np.array(prediction).astype(int).reshape(256,2,2)\n",
    "        for i in range(256):\n",
    "            cv2.line(img, (prediction[i,0,0],i), (prediction[i,0,1],i), 255, 1)\n",
    "            cv2.line(img, (prediction[i,1,0],i), (prediction[i,1,1],i), 255, 1)\n",
    "\n",
    "        cv2.imwrite('prediction_HOB_GTpic2\\\\' + name, img)# change save path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function load at 0x000002AAD796DDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function load at 0x000002AAD796DDC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# start = time.time()\n",
    "# save_predictions()\n",
    "# end = time.time()\n",
    "# print(end - start)\n",
    "save_predictions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
